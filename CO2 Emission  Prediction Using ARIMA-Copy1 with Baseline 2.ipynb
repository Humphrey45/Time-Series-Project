{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b054bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab\n",
    "import seaborn as sns\n",
    "import pmdarima as pm\n",
    "import itertools \n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pmdarima import auto_arima\n",
    "color_pal = sns.color_palette()\n",
    "from flask import Flask, request, jsonify\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d37fe0",
   "metadata": {},
   "source": [
    "# LOADING AND VIEWING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a70b9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading the dataset using def fuction and making sure of few things like:\n",
    "#parse_dates enables pandas to understand that it is a date and not string\n",
    "def gb_carbon():\n",
    "    # Read the CSV file and parse the dates\n",
    "    data = pd.read_csv('gb_carbon_intensity.csv', parse_dates=True)\n",
    "    data.set_index('datetime', inplace=True)\n",
    "    return data\n",
    "\n",
    "CO2 =gb_carbon()\n",
    "print(CO2.head()) #checking the first data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CO2.tail()) #checking the last five data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c2cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(CO2.info()) #Checking the information of each columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a8504",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503518b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#The datetime shows a timespam of 30minutes interval and I will split it based on that\n",
    "# 30min, 1 hour, day_of_week, month, quarter, year, day_of_year.\n",
    "def create_timespam(CO2):\n",
    "    if not pd.api.types.is_datetime64_any_dtype(CO2.index):\n",
    "        CO2.index = pd.to_datetime(CO2.index)\n",
    "        \n",
    "    CO2['30mi'] = CO2.index.floor('30T').time # this is to split it into 30min but it will be an object instead of a float\n",
    "    CO2['30min'] = CO2['30mi'].apply(lambda x: x.hour * 60 + x.minute + x.second / 60) #For the 30mins to be a float\n",
    "    CO2.drop(columns=['30mi'], inplace=True)\n",
    "    CO2['hour'] = CO2.index.hour\n",
    "    CO2['dayofweek'] = CO2.index.dayofweek\n",
    "    CO2['month'] = CO2.index.month\n",
    "    CO2['quarter'] = CO2.index.quarter\n",
    "    CO2['year'] = CO2.index.year\n",
    "    CO2['dayofyear'] = CO2.index.dayofyear\n",
    "    # Every other time split will have the right datatype \n",
    "    return CO2\n",
    "CO2 = create_timespam(CO2)\n",
    "CO2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have to drop, forecast and the index columns  \n",
    "CO2.drop(columns=['index', 'forecast'], inplace=True)\n",
    "# print(CO2.head())\n",
    "CO2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04462a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "CO2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c936619",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Seeing that some rows has 'NaN' I will remove the empyt rows 'NaN'\n",
    "#These NaNs rows was created but had not yet been retrived when the data was downloaded from the website\n",
    "CO2.dropna(inplace=True)\n",
    "CO2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5891d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to check if there is still NaN's in the dataset\n",
    "CO2_has_nan = CO2.isnull().values.any()\n",
    "print(f\"Does the dataset have NaN values? {CO2_has_nan}\") # to reconfirm if there is still any 'NaNs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a31e62c",
   "metadata": {},
   "source": [
    "# PERFORM SPECIFIC ATA ANALYSIS (SDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,8))\n",
    "sns.boxplot(data=CO2, x='30min', y='actual')\n",
    "ax.set_title('CO2 Emission by 30minutes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55417b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "sns.boxplot(data=CO2, x='hour', y='actual')\n",
    "ax.set_title('CO2 Emission by hour')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7015e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.boxplot(data=CO2, x='dayofweek', y='actual')\n",
    "ax.set_title('CO2 Emission by days of the week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.boxplot(data=CO2, x='month', y='actual')\n",
    "ax.set_title('CO2 Emission by month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.boxplot(data=CO2, x='quarter', y='actual')\n",
    "ax.set_title('CO2 Emission by quarter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.boxplot(data=CO2, x='year', y='actual')\n",
    "ax.set_title('CO2 Emission by year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(28,10))\n",
    "sns.boxplot(data=CO2, x='dayofyear', y='actual')\n",
    "ax.set_title('CO2 Emission by days of the year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5380822a",
   "metadata": {},
   "source": [
    "# TO DETERMINE IF THE DATA IS STATIONARY OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2a63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# METHOD 1: using visualization to see if the data (the 'actual' column which is my focus) is stationary or not\n",
    "\n",
    "plt.rcParams['font.size'] = 15\n",
    "CO2['actual'].plot(figsize=(15,5), color=color_pal[0], title = 'Great Britain CO2 Current emission');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db8289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHOD 2: using adfuller to determine if the 'actual' column is stationary or not\n",
    "\n",
    "def stationarity_check(actual):\n",
    "    \"\"\"\n",
    "    Check if the 'actual' column is stationary  using function.\n",
    "    \"\"\"\n",
    "    # Performed the Augmented Dickey-Fuller test\n",
    "    result = adfuller(actual, autolag = 'AIC')\n",
    "    print('1. ADF :', result[0])\n",
    "    print('2. P_value: ', result[1])\n",
    "    print('3. Num. of Lags: ', result[2])\n",
    "    print('4. Num. of observation: ', result[3])\n",
    "    print('5. Critical value :')\n",
    "    for key, values in result[4].items():\n",
    "        print('\\t', key, ': ', values)\n",
    "    \n",
    "    # To determine from the result of p-value if 'actual' column is stationary or not\n",
    "    if result[1] < 0.05:\n",
    "        print(\"The actual column is stationary (Therefore, reject null hypothesis)\")\n",
    "    else:\n",
    "        print(\"The actual column is non-stationary (Therefore, fail to reject null hypothesis)\")\n",
    "        \n",
    "stationarity_check(CO2['actual'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7c7be",
   "metadata": {},
   "source": [
    "# CREATING TIME SERIES MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48185dd",
   "metadata": {},
   "source": [
    "### SPLIT THE DATA INTO TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time Series Cross Validation to split the data\n",
    "#The goal is to get 30-minute intervals in the last 3 months\n",
    "tss = TimeSeriesSplit(n_splits=5, test_size=4320, gap=48) #The split is done with 30 min interval to predict the last 3 months\n",
    "CO2 = CO2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee5ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This to get my train and validation index using the timeseriessplit i used in the previous cell\n",
    "for arima_train_idex, arima_vali_idex in tss.split(CO2):\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69947115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#My train index output\n",
    "arima_train_idex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8198410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my validation(test) index output\n",
    "arima_vali_idex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67842dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The goal of this code is to use the 'forecast' column already on the data and compare it with my forecast\n",
    "# The 'forecast' column is the result from the website i downloaded my data. I want to see which prediction is most accurate  \n",
    "#TimeSeriesSplit\n",
    "tss = TimeSeriesSplit(n_splits=5, test_size=4320, gap=48)\n",
    "CO2 = CO2.sort_index()\n",
    "\n",
    "for arima_train_idex, arima_vali_idex in tss.split(CO2):\n",
    "    break \n",
    "\n",
    "# Visualizing my TimeSeriesSplit\n",
    "fig, axs = plt.subplots(5, 1, figsize=(15, 15), sharex=True)\n",
    "\n",
    "cell = 0\n",
    "splits = []\n",
    "for arima_train_index, arima_test_index in tss.split(CO2):\n",
    "    arima_train = CO2.iloc[arima_train_index]\n",
    "    arima_test = CO2.iloc[arima_test_index]\n",
    "    splits.append((arima_train, arima_test)) \n",
    "    \n",
    "    arima_train['actual'].plot(ax=axs[cell], label='Training Set', title=f'Data Train/Test Split cell {cell}')\n",
    "    arima_test['actual'].plot(ax=axs[cell], label='Test Set')\n",
    "    axs[cell].axvline(arima_test.index.min(), color='black', ls='--')\n",
    "    cell += 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This helps me to get all the possible comnibation in the list element\n",
    "p = range(0, 2)\n",
    "d = range(0, 2)\n",
    "q = range(0, 2)\n",
    "\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "print(seasonal_pdq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df253e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder for my data\n",
    "CO2 = CO2['actual']\n",
    "\n",
    "# search over the parameters above\n",
    "for param in pdq:\n",
    "    for param_sea in seasonal_pdq:\n",
    "        try:\n",
    "            # my model section\n",
    "            model = sm.tsa.statespace.SARIMAX(CO2,\n",
    "                                             order=param,\n",
    "                                             seasonal_order=param_sea,\n",
    "                                             enforce_stationarity=False,\n",
    "                                             enforce_invertibility=False)\n",
    "            # model fit\n",
    "            results = model.fit()\n",
    "            # results output\n",
    "            print(f'SARIMAX{param}x{param_sea} - AIC: {results.aic}')\n",
    "        except Exception as e:\n",
    "            # Print the exception if any occurs\n",
    "            print(f'Error for SARIMAX{param}x{param_sea}: {e}')\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b8e28",
   "metadata": {},
   "source": [
    "FITTING THE BEST PARAMETER INTO THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9c7d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Based on the training above, the best  is SARIMAX(1, 1, 1)x(1, 0, 1, 12) - AIC: 708999.2968599194\n",
    "# Define the model with the identified best parameters\n",
    "arima_best_model = sm.tsa.statespace.SARIMAX(CO2,\n",
    "                                             order=(1, 1, 1),\n",
    "                                             seasonal_order=(1, 0, 1, 12),\n",
    "                                             enforce_stationarity=False,\n",
    "                                             enforce_invertibility=False)\n",
    "\n",
    "# Fit the model\n",
    "results = arima_best_model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebe4c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#diagnostics to see how the data plays out\n",
    "results.plot_diagnostics(figsize=(15,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205d7eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checking for confidence interval (lower and upper values )\n",
    "# May is the starting of my 3 month. my data ends in July based on the data\n",
    "# so, i want to predict from May... \n",
    "pred =results.get_prediction(start=pd.to_datetime('2024-05-07 00:00:00'), dynamic=False) \n",
    "pred_ci =pred.conf_int()\n",
    "pred_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa00cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CO2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1fb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to predict the last 3 months and compare it with actual value to see the accuracy\n",
    "start_date = '2024-05-07' #start of my testing part\n",
    "\n",
    "# Get in-sample predictions from the test date onwards\n",
    "pred = results.get_prediction(start=start_date, dynamic=False)\n",
    "\n",
    "# Extract the predicted mean values\n",
    "y_predicted = pred.predicted_mean\n",
    "\n",
    "# Actual values from the starting date onwards\n",
    "y_truth = CO2[start_date:].copy()\n",
    "\n",
    "# Combining actual and predicted values to see side by side comparison\n",
    "CO2_comparison = pd.DataFrame({\n",
    "    'actual': y_truth,\n",
    "    'predicted': y_predicted\n",
    "})\n",
    "\n",
    "# Display the comparison\n",
    "print(CO2_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d1397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since my data has multiple columns, including 'forecast' and 'actual', i will focus on these\n",
    "# I want to predict the last 3 months and compare it with actual value to see the accuracy\n",
    "start_date = '2024-05-07' #start of my testing part\n",
    "\n",
    "# Get predictions starting from the defined start date\n",
    "pred = results.get_prediction(start=start_date, dynamic=False)\n",
    "\n",
    "# Extract the predicted mean values\n",
    "y_predicted = pred.predicted_mean\n",
    "\n",
    "# Extract actual values from the start date onwards\n",
    "y_truth = CO2['actual'][start_date:].copy()\n",
    "\n",
    "# Extract the forecast values from the start date onwards\n",
    "y_forecast = CO2['forecast'][start_date:].copy()\n",
    "\n",
    "# Align indices of the series\n",
    "y_predicted = y_predicted.reindex(y_truth.index)\n",
    "y_forecast = y_forecast.reindex(y_truth.index)\n",
    "\n",
    "# Combine actual, forecast, and predicted values into a DataFrame\n",
    "CO2_comparison = pd.DataFrame({\n",
    "    'actual': y_truth,\n",
    "    'forecast': y_forecast,\n",
    "    'predicted': y_predicted\n",
    "})\n",
    "\n",
    "# Display the comparison\n",
    "print(CO2_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00b868",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To visualize Twelve-weeks period to see how well the model performed\n",
    "start_date = '2024-05-07'\n",
    "\n",
    "# Filter my data for the Twelve-weeks period\n",
    "end_date = pd.to_datetime(start_date) + pd.DateOffset(weeks=12)\n",
    "Twelve_weeks_CO2 = CO2_comparison[start_date:end_date]\n",
    "\n",
    "# Plotting the actual vs predicted values for Twelve weeks\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(Twelve_weeks_CO2.index, Twelve_weeks_CO2['actual'], label='Actual CO2')\n",
    "plt.plot(Twelve_weeks_CO2.index, Twelve_weeks_CO2['predicted'], label='Predicted CO2', linestyle='--')\n",
    "plt.title('Actual vs Predicted CO2 Emission (12 Weeks)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('CO2 Emission values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a5885b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract actual and predicted values to enable me calculate the accurancy\n",
    "y_actual = CO2_comparison['actual']\n",
    "y_predicted = CO2_comparison['predicted']\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_actual, y_predicted)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_actual, y_predicted)\n",
    "\n",
    "# Calculate R-squared (R²)\n",
    "r2 = r2_score(y_actual, y_predicted)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Predicted Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Predicted Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Predicted R-squared (R²): {r2:.4f}\")\n",
    "print(f\"Predicted Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c28544d0",
   "metadata": {},
   "source": [
    "1. MSE measures the average of the squared differences between predicted values and actual values. The MSE of 22.9993 suggests that there is some level of variance or error in my model's predictions for CO2 emissions. The lower, the better.\n",
    "\n",
    "2. On MAE, this means, on average, my predictions for CO2 emissions are off by about 3.4651 units from the actual values.\n",
    "\n",
    "3. R-squared measures the proportion of the variance in the dependent variable (CO2 emissions) that is predictable from the independent variables (in my features). R2 score of 0.9885 indicates that my model explains 98.85% of the variance in the observed data. This is the best model performance among the other two models.\n",
    "\n",
    "4. On RMSE, this indicates that approximately RMSE is off by about 4.7958 units from the actual values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a130f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to compare the forecast that I saw when i downloaded the data aganist my forecast to see which is better\n",
    "#I will call this baseline 2 while the actual result of CO2 will be called baseline 1\n",
    "# the baseline is always the same across the both model so there will be no need to check for Prophet model.\n",
    "# based on this, the result gotten here will be used for compare aganist the prophet model \n",
    "# To get my baseline from the forecast that was already in the dataset\n",
    "\n",
    "# Get the last observed value in the training set\n",
    "last_observed_value = CO2[start_date].iloc[-1]\n",
    "\n",
    "# Create a baseline prediction for the same length as the test period\n",
    "baseline_pred = [last_observed_value] * len(y_actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0729086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CO2_comparison.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the forecast and actual values\n",
    "y_forecast = CO2_comparison['forecast']\n",
    "y_actual = CO2_comparison['actual']\n",
    "\n",
    "# Calculate the error metrics for the baseline forecast\n",
    "mse_forecast = mean_squared_error(y_actual, y_forecast)\n",
    "mae_forecast = mean_absolute_error(y_actual, y_forecast)\n",
    "r2_forecast = r2_score(y_actual, y_forecast)\n",
    "rmse_forecast = np.sqrt(mse_forecast)\n",
    "\n",
    "# Print the ARIMA metrics (i have already written this code earlier)\n",
    "print(f\"Predicted Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Predicted Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Predicted R-squared (R²): {r2:.4f}\")\n",
    "print(f\"Predicted Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "\n",
    "# Print the baseline metrics\n",
    "print(f\"Baseline Forecast - Mean Squared Error (MSE): {mse_forecast:.4f}\")\n",
    "print(f\"Baseline Forecast - Mean Absolute Error (MAE): {mae_forecast:.4f}\")\n",
    "print(f\"Baseline Forecast - R-squared (R²): {r2_forecast:.4f}\")\n",
    "print(f\"Baseline Forecast - Root Mean Squared Error (RMSE): {rmse_forecast:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4a0ee",
   "metadata": {},
   "source": [
    "# The END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
